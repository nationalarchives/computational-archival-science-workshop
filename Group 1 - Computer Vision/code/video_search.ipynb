{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "from zipfile import ZipFile\n",
    "from utils.helper import get_all_files, get_all_dirs, make_new_dir\n",
    "from utils.extractor import Extractor\n",
    "from PIL import Image\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.video_tools import FeatExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_path(my_dir):\n",
    "    \"\"\"replace white space with underscore '_' in files and directories under my_dir\n",
    "    Note: only files/dirs inside my_dir are checked. Parent directories above my_dir are ignored.\n",
    "    \"\"\"\n",
    "    sep = os.path.sep\n",
    "    dir_lst = get_all_dirs(my_dir, trim=1)\n",
    "    tree_depth = max([len(p.split(sep)) for p in dir_lst])\n",
    "    dcount = 0\n",
    "    for i in range(1):#tree_depth):  # repeat the path fixing process several times \n",
    "        dir_lst = get_all_dirs(my_dir, trim=1)[::-1]\n",
    "        for p in dir_lst:\n",
    "            leaf = p.split(sep)[-1]\n",
    "            parent = os.path.dirname(p)\n",
    "            new_leaf = leaf.replace(' ','_')\n",
    "            if new_leaf != leaf and os.path.exists(os.path.join(my_dir, p)):\n",
    "                print('Renaming \"%s\" to \"%s\"' % (p, os.path.join(parent, new_leaf)))\n",
    "                shutil.move(os.path.join(my_dir, p), os.path.join(my_dir, parent, new_leaf))\n",
    "                dcount += 1\n",
    "    file_lst = get_all_files(my_dir, trim=0)\n",
    "    fcount = 0\n",
    "    for f in file_lst:\n",
    "        leaf = f.split(sep)[-1]\n",
    "        parent = os.path.dirname(f)\n",
    "        new_leaf = leaf.replace(' ', '_')\n",
    "        if new_leaf != leaf:\n",
    "            print('Renaming \"%s\" to \"%s\"' % (f, os.path.join(parent, new_leaf)))\n",
    "            shutil.move(f, os.path.join(parent, new_leaf))\n",
    "            fcount += 1\n",
    "    print('Done. Rename %d dirs and %d files' % (dcount, fcount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = '/home/tb0035/projects/tna_datathon/data/LOC_Videos'\n",
    "OUT = '/home/tb0035/projects/tna_datathon/data/out'\n",
    "make_new_dir(OUT, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Rename 0 dirs and 0 files\n"
     ]
    }
   ],
   "source": [
    "fix_path(DATA_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_img_formats = ['jpg', 'png', 'gif', 'bmp']\n",
    "accepted_vid_formats = ['mp4', 'avi', 'flv', 'mov', 'mkv', 'mpeg']\n",
    "loc_vid = get_all_files(DATA_ROOT, trim=1)\n",
    "loc_vid = [vid for vid in loc_vid if vid.split('.')[-1].lower() in accepted_vid_formats]\n",
    "loc_vid_tab = pd.DataFrame(columns=['path', 'type'])\n",
    "loc_vid_tab['path'] = loc_vid\n",
    "loc_vid_tab['type'] = ['video',] * len(loc_vid)\n",
    "loc_vid_tab.to_csv(os.path.join(DATA_ROOT, 'list.txt'), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = pd.read_csv(os.path.join(DATA_ROOT, 'list.txt'))\n",
    "paths = lst['path'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/tb0035/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
      "102858752/102853048 [==============================] - 39s 0us/step\n"
     ]
    }
   ],
   "source": [
    "batchsize = 2\n",
    "min_frames = 3\n",
    "arch = 'ResNet50'\n",
    "stride_in_sec = 0.5\n",
    "extractor = FeatExtractor(batchsize = batchsize, min_frames = min_frames,\n",
    "                              arch = arch,\n",
    "                              verbose = False, stride_in_sec = stride_in_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Volunteering_message_JONATHAN_EDWARDS.mp4\n",
      "Processing Journey_-_Test_Event_montage.mp4\n",
      "Processing Pin_badges.mp4\n",
      "Processing Overall_Highlights_FINAL.mp4\n"
     ]
    }
   ],
   "source": [
    "sep = os.path.sep\n",
    "feat_paths = []\n",
    "for path in paths:\n",
    "    print('Processing %s' % path)\n",
    "    name = path.split(sep)[-1].split('.')[0]\n",
    "    np_out = os.path.join(OUT, name + '.npy')\n",
    "    extractor.extract(os.path.join(DATA_ROOT, path), np_out, False)\n",
    "    feat_paths.append(name + '.npy')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
